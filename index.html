<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<meta name="google-site-verification" content="3BouWQjT3khTNTDie34KfI1k-Gu8gAOEA8rm9izS3us" />
    <title>Sophie Ostmeier</title>

    <meta name="author" content="Sophie Ostmeier">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/Telescope.webp" type="image/webp">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Sophie Ostmeier
                </p>
                <p>
I am a CS master's student and research assistant at Stanford University, where I work at the <a href="https://aimi.stanford.edu">AIMI Center</a>.
From 2023 to 2025 I was funded by the German Research Foundation (DFG). Before Stanford, I completed an M.D. and Dr.med. at the Technical University of Munich.
<br><br>
Outside the lab you will find me running, cycling, bikepacking, swimming, playing pickleball, or hiking. I follow a wide range of sports—especially tennis, triathlon, and track & field—but I can appreciate almost any activity with movement.
                </p>
                <p style="text-align:center">
                  <a href="mailto:ostmeiersophie@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=Q2SCA-sAAAAJ&hl=en&authuser=1">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://profiles.stanford.edu/sophie-ostmeier">Stanford Profile</a> &nbsp;/&nbsp;
                  <a href="https://github.com/SophieOstmeier">Github</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/sophie-ostmeier">LinkedIn</a> 
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/sophieostmeier.JPG"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/SophieOstmeier.JPG" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  My research focuses on how machine-learning models learn, make predictions and how we measure that, with a current emphasis on vision and/or language models. I am also curious about reinforcement learning as a path toward intelligent decision-making systems and wonder how they would do medicine.<br><br>

                  <!-- I'm interested in machine intelligence and how we design this intelligence to achieve safe and reliable automatic decision-making systems in high stake fields.  -->
                  <!-- Some papers are <span class="highlight">highlighted</span>. -->
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Some recent papers (<a href="https://scholar.google.com/citations?user=Q2SCA-sAAAAJ&hl=en&authuser=1">Google Scholar</a>)</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


    <tr bgcolor="#ffffd0" onmouseout="video_stop()" onmouseover="video_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <video id="liere_video" width="160" height="160" muted loop style="filter: brightness(1.5);">
          <source src="images/liere_wheel.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
        <script type="text/javascript">
          function video_start() {
            document.getElementById('liere_video').play();
          }

          function video_stop() {
            document.getElementById('liere_video').pause();
          }
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2406.10322">
          <span class="papertitle">LieRE: Lie Rotational Positional Encodings</span>
        </a>
        <br>
        <strong>Sophie Ostmeier</strong>,
        <a href="https://cs.stanford.edu/people/baxelrod/">Brian Axelrod</a>,
        <a href="https://maya-varma.com">Maya Varma</a>,
        <a href="https://profiles.stanford.edu/michael-moseley">Michael Moseley</a>,
        <a href="https://med.stanford.edu/mimi/people/CurrentLab.html">Akshay Chaudhari</a>,
        <a href="https://curtlanglotz.com">Curtis Langlotz</a>,
        <br>
        <em>ICML</em>, 2025
        <!-- <br>
        <a href="https://szymanowiczs.github.io/bolt3d">project page</a> -->
        /
        <a href="https://arxiv.org/abs/2406.10322">arXiv</a>
        <p></p>
        <p>
            We extend the rotational positional encodings widely used in large language models to high-dimensional rotation matrices by exploiting their Lie-group structure, and we test this approach on both 2-D and 3-D vision tasks.
        </p>
      </td>
    </tr>

      <tr onmouseout="cvpr12_stop()" onmouseover="cvpr12_start()">
        <td style="padding:16px;width:20%;vertical-align:middle">
          <div class="one" style="height: 160px; width: 160px;">
            <div class="two" id='cvpr12_image' style="height: 160px; width: 160px;">
              <img src='images/green_shades_1.png' style="border-style: none; width: 160px; height: 160px; object-fit: cover;">
            </div>
            <img src='images/green_shades_2.png' style="border-style: none; width: 160px; height: 160px; object-fit: cover;">
          </div>
          <script type="text/javascript">
            function cvpr12_start() {
              document.getElementById('cvpr12_image').style.opacity = "1";
            }

            function cvpr12_stop() {
              document.getElementById('cvpr12_image').style.opacity = "0";
            }
            cvpr12_stop()
          </script>
        </td>
        <td style="padding:8px;width:80%;vertical-align:middle">
          <a href="https://aclanthology.org/2024.findings-emnlp.21/">
            <span class="papertitle">GREEN: Generative Radiology Report Evaluation and Error Notation</span>
          </a>
          <br>
          <strong>Sophie Ostmeier</strong>,<a href="https://cs.stanford.edu/people/baxelrod/">Justin Xu</a>,
          <a href="https://cs.stanford.edu/people/baxelrod/">Zhihong Chen</a>,
        <a href="https://maya-varma.com">Maya Varma</a>,
        <a href="https://www.linkedin.com/in/louis-blankemeier/">Louis Blankemeier</a>,
        <a href="https://www.linkedin.com/in/bluethgen/">Christian Bluethgen</a>,
        <a href="https://www.linkedin.com/in/arne-michalson-md-2b3aa2271/">Arne Edward Michalson</a>,
        <a href="https://profiles.stanford.edu/michael-moseley">Michael Moseley</a>,
        <a href="https://curtlanglotz.com">Curtis Langlotz</a>,
        <a href="https://med.stanford.edu/mimi/people/CurrentLab.html">Akshay Chaudhari</a>,
        <a href="https://jbdel.github.io">Jean-Benoit Delbrouck</a>,
          <br>
          <em>EMNLP, Findings</em>, 2024
          <br>
          <a href="https://stanford-aimi.github.io/green.html">project website</a> /
          <a href="https://huggingface.co/datasets/StanfordAIMI/GREEN">data</a> /
          <a href="https://huggingface.co/StanfordAIMI/GREEN-RadLlama2-7b">model</a>
          <p>We present GREEN, an open-source metric that employs language models to spot and explain clinically significant errors in radiology reports, yielding expert-aligned scores, interpretable feedback, and commercial-grade performance.</p>
        </td>
      </tr>

      <tr onmouseout="use_stop()" onmouseover="use_start()">
        <td style="padding:16px;width:20%;vertical-align:middle">
          <div class="one" style="height: 160px; width: 160px;">
            <div class="two" id='use_image' style="height: 160px; width: 160px;">
              <img src='images/uncertain_1.png' style="border-style: none; width: 160px; height: 160px; object-fit: cover;">
            </div>
            <img src='images/uncertain_2.png' style="border-style: none; width: 160px; height: 160px; object-fit: cover;">
          </div>
          <script type="text/javascript">
            function use_start() {
              document.getElementById('use_image').style.opacity = "1";
            }

            function use_stop() {
              document.getElementById('use_image').style.opacity = "0";
            }
            use_stop()
          </script>
        </td>
        <td style="padding:8px;width:80%;vertical-align:middle">
          <a href="https://arxiv.org/pdf/2209.13008">
            <span class="papertitle">USE-Evaluator: Performance metrics for medical image segmentation models supervised by uncertain, small or empty reference annotations</span>
          </a>
          <br>
          <strong>Sophie Ostmeier</strong>,
          <a href="https://cs.stanford.edu/people/baxelrod/">Brian Axelrod</a>,
          Fabian Isensee,
          Jeroen Bertels,
          Michael Mlynash,
          Soren Christensen,
          Maarten G Lansberg,
          Gregory W Albers,
          Rajen Sheth,
          Benjamin FJ Verhaaren,
          Abdelkader Mahammedi,
          Li-Jia Li,
          Greg Zaharchuk,
          Jeremy J Heit
          <br>
          <em>Medical Image Analysis</em>, 2023
          <br>
          <a href="https://arxiv.org/pdf/2209.13008">arXiv</a> /
          <a href="https://github.com/SophieOstmeier/USE-Evaluator">code</a>
          <p>We investigate evaluation metrics for medical image segmentation that account for uncertainty, small structures, and empty reference annotations.</p>
        </td>
      </tr>

          </tbody></table>

          
					<table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
            <tr>
              <td>
                <h2>Miscellaneous</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #c6b89e;">
								 <h2>Academic Service</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
					<a href="https://clinicalmllms.github.io">Co-Organizer of Workshop on Multimodal LLMs in clinical Practice (MICCAI 2025),<br>
				  <a href="https://sites.google.com/view/miccai-2025-tutorial">Speaker at Foundation to Multimodal Models for Medical Imaging (FMLLM) Tutorial (MICCAI 2025),<br>
				  Reviewer (ICLR 2026)<br>
              </td>
            </tr>
						
           
            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #edd892;">
								 <h2>Teaching</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                Lecturer, Stanford BioE 224, "AI in medical imaging" (2024, 2025)<br>,
				  Stanford AIMI Center Summer Camp Mentor (2024, 2025)<br>,
				Stanford Small Science Groups (2023)<br>
              </td>
            </tr>
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:center;font-size:small;">
                  Website Template <a href="https://github.com/jonbarron/jonbarron_website">source code</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
<div style="display:flex; justify-content:center; align-items:center; width:500px; height:250px; overflow:hidden; margin: 0 auto;">
  <div style="transform: scale(0.5); transform-origin: center;">
    <script type="text/javascript" id="mapmyvisitors"
      src="//mapmyvisitors.com/map.js?d=EXpyB-cyZ6eO3oqWdGKhdvFAkDlV2qSEde2PxCcWXlI&cl=ffffff&w=a">
    </script>
  </div>
</div>

  </body>
</html>
